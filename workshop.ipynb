{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.1\n",
    "\n",
    "def cauchy_loss(x):\n",
    "    global c\n",
    "    f = np.log1p(np.square(x / c) / 2)\n",
    "\n",
    "    return f\n",
    "\n",
    "def smooth_l1(x):\n",
    "    global c\n",
    "    f = np.sqrt(np.square(x / c) + 1) - 1\n",
    "\n",
    "    return f\n",
    "\n",
    "def gemanmcclure(x):\n",
    "    global c\n",
    "\n",
    "    xx = np.square(x / c)\n",
    "    f = 2 * xx / (xx + 4)\n",
    "    return f\n",
    "\n",
    "def welsch(x):\n",
    "    global c\n",
    "\n",
    "    xx = np.square(x / c)\n",
    "    f = 1 - np.exp(-xx / 2)\n",
    "    return f\n",
    "\n",
    "x = np.linspace(-3.5 * c, 3.5 * c, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(function, title):\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.plot(x, function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [cauchy_loss, smooth_l1, gemanmcclure, welsch]\n",
    "titles = [\"Cauchy Loss\", \"Another SmoothL1\", \"Geman-Mcclure Loss\", \"Welsch Loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.suptitle(\"Robust Regresion Losses\")\n",
    "\n",
    "ax1.plot(x, cauchy_loss(x))\n",
    "ax1.set_title(\"Cauchy Loss\")\n",
    "\n",
    "ax2.plot(x, smooth_l1(x))\n",
    "ax2.set_title(\"Another SmoothL1 Loss\")\n",
    "\n",
    "ax3.plot(x, gemanmcclure(x))\n",
    "ax3.set_title(\"Geman-McClure Loss\")\n",
    "\n",
    "ax4.plot(x, welsch(x))\n",
    "ax4.set_title(\"Welsch Loss\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, cauchy_loss(x), label=titles[0])\n",
    "ax.plot(x, smooth_l1(x), label=titles[1])\n",
    "ax.plot(x, gemanmcclure(x), label=\"Geman-McClure Loss\")\n",
    "ax.plot(x, welsch(x), label=titles[3])\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.legend(bbox_to_anchor =(.93, 1.18), ncol = 2)\n",
    "plt.rcParams['figure.dpi'] = 350\n",
    "plt.rcParams['savefig.dpi'] = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VAE\n",
    "from dataset import CIFARDataset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "model.load_state_dict(torch.load(\"autoencoder_weights/reconstruction_loss_best_autoencoder.pt\", map_location=torch.device('cpu')))\n",
    "dataset = CIFARDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.Tensor(dataset[0][0]).unsqueeze(0)\n",
    "model.eval()\n",
    "samples = model(samples)\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = model.sample(1, torch.device(\"cpu\")).detach().numpy()\n",
    "#samples = dataset[0][0]\n",
    "samples = np.squeeze(samples.detach().numpy(), 0)\n",
    "samples = samples.transpose(1, 2, 0)\n",
    "plt.imshow(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks import CauchyLoss, WelschLoss, AnotherSmoothL1Loss, GemanMcClureLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = GemanMcClureLoss()\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    x, y = torch.rand(1, 3, 32, 32, requires_grad=True), torch.rand(1, 3, 32, 32)\n",
    "    out = loss(x, y)\n",
    "    out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import EmbeddingSearch, plot_3d\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "e = EmbeddingSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels = e.embeddings, e.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = mds.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import base_config, autoencoder_config, classifier_config\n",
    "import matplotlib\n",
    "from matplotlib import cm, ticker\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vvisualize_embeddings(embeddings, labels, num_categories=classifier_config.num_classes):\n",
    "    threshold = base_config.visualization_threshold\n",
    "    if len(embeddings) > threshold:\n",
    "        embeddings = embeddings[:threshold, :]\n",
    "        labels = labels[:threshold]\n",
    "    \n",
    "    cmap = cm.get_cmap('tab20')\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for label in range(num_categories):\n",
    "        indexes = labels == label\n",
    "        ax.scatter(embeddings[indexes, 0], embeddings[indexes, 1], embeddings[indexes, 2], c=np.array(cmap(label)).reshape(1, 4), label = label, alpha=0.5)\n",
    "    \n",
    "    plt.savefig(f'images/embeddings_{autoencoder_config.loss_function}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
